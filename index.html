
<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>ale x)</title>
  
  <meta name="description" content="Alex's website">
  <meta name="author" content="Alex Ionkov">
  <meta name="keywords" content="Ionkov, Alex, Alexander">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <link rel="stylesheet" href="styles.css">
</head>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-BKBXJ8J9KS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-BKBXJ8J9KS');

  function toggle(id) {
  a = document.getElementById('toggle_'+id);
  b = document.getElementById('display_'+id);
    if (a.style.display=='block') {
      a.style.display='none';
      b.innerHTML='About >';
    }
    else {
      a.style.display='block';
      b.innerHTML='About ^';
  }
}
</script>

<body>
<div id="main_container">

  <h4> My name is Alex Ionkov. &nbsp;&nbsp;&nbsp;
    <a href="https://twitter.com/i0nif" target="_blank">Twitter</a>
    <a href="http://github.com/ionif" target="_blank">GitHub</a>
    <a href="http://www.linkedin.com/in/aionkov" target="_blank">LinkedIn</a>
  </h4>
  <a id="display_3234" href="javascript:toggle('3234');">About ></a> 
<div id="toggle_3234" style="display: none">I am a Software Engineer. My interests include human computer interaction (HCI), augmented and virtual reality (AR/VR), and user interface/user experience (UI/UX). I am extremely passionate about innovative interaction design. In the past, I worked as a Student Developer at the Kodi Foundation for Google Summer of Code 2020 and as a undergraduate in the UW Graphics Group. I have also worked on RNA sequencing projects at the Morgridge Institute for Research under John Steill and at Los Alamos National Laboratory on parameter fitting optimizations for cell signaling models under William Hlavacek and Ryan Suderman. </p> <p>For more information, see my <a href="resume.pdf">[CV]</a>, <a href="https://scholar.google.com/citations?user=tT9X2QMAAAAJ&hl=en">[Google Scholar]</a>, or <a href="https://github.com/ionif">[Github]</a>.</div>
<!--row-->
<div class="row">
  <!--left-->
  <div class="column left">
    <h4>Vision Smartphone Passthrough Glasses</h4>
    <p> 3D printed wearable Google Cardboard style glasses for use with smartphone. </p>
    <p>Currently compatible with WebXR (WebVR), Aframe, Google Cardboard. Fits the iPhone 11, X or any phone of similar dimension (~5.95" by ~2.95" by ~0.35"). I am currently using Google Mediapipe and Tensorflow for the hand tracking computer vision and Three.js for rendering. The goal is to create essentially a cheap Hololens using just a smartphone, a 3D printed part, and computer vision. The website is at <a href="ionif.github.io/vision/">ionkov.com/vision</a> and the Github repo is <a href="https://github.com/ionif/visionglasses">here.</a></p>
    <p> I post regular updates to my Twitter <a href="https://twitter.com/i0nif" tarsget="_blank">@i0nif</a>.</p>
  </div>
  <!--right-->
  <div class="column right">
    <img src="assets/img/dragndrop.gif" loading="lazy" alt="vision demo">
  </div>
</div>

<!--row-->
<div class="row">
  <!--left-->
  <div class="column left">
    <h4>Rigme.io</h4>
    <p> My friend, Jas, and I created <a href="rigme.io">rigme.io</a>(now dead x/), which allowed you to take a picture of yourself with your webcam and we would send you an email back with a 3D rigged model of you. We used the PiFuHD model and Blender to do the rigging. The Github repo is <a href="https://github.com/tonightio/rigme">here.</a></p>
  </div>
  <!--right-->
  <div class="column right">
    <img src="assets/img/rigme.png" loading="lazy" alt="rigme pipeline">
  </div>
</div>

<!--row-->
<div class="row">
  <!--left-->
  <div class="column left">
    <h4>Kodi (XBMC)</h4>
    <p>I was accepted to Google Summer of Code @ Kodi(XBMC). My mentor, Razzee, and I spent the summer writing a new web interface for Kodi in Elm called elm-chorus. Elm-chorus supports live playback and organization of media over web sockets using the JSON-RPC API. The Medium reflection I wrote is <a href="https://medium.com/@aionkov/google-summer-of-code-2020-kodi-reflection-9a3aaffab1f7">here</a> and the Github repo is <a href="https://github.com/xbmc/elm-chorus">here.</a></p>
  </div>
  <!--right-->
  <div class="column right">
    <img src="assets/img/demo.gif" loading="lazy" alt="vision demo">
  </div>
</div>

<h3>more projects: </h3>
<ul>
  <li><div class="row">
  <!--left-->
  <div class="column left">
    <p><a href="https://github.com/ionif/posenetToThreejs">posenetToThreejs</a>: I connected Tensorflow.js Posenet to a Three.js Humanoid Model using SocketIO. The pose keypoints are then mapped to the humanoid rig so that you can control it with your body. 2020.</p>
  </div>
  <!--right-->
  <div class="column right">
    <img src="assets/img/posenet.gif" loading="lazy" alt="vision demo">
  </div>
</div></li>
  <li><p><a href="assets/js/grtown.html">GraphicsTown</a>: CS559 Computer Graphics Final project. I used Three.js to create a bustling island town with a trolley that travels on a spline.</p></li>
  <li><p><a href="https://github.com/ionif/Transpos">Transpos</a>: Transpos is an app written for iOS in Swift which would recognize an image and display a respective 3D model over them. My friend Jas and I made it using Firebase to map images to 3D models and ARKit for the augmented reality aspect. 2019.</p></li>
  <li><p><a href="https://github.com/lanl/PyBNF">PysBioNetFit</a>: Collaborated in a three-person team that developed an application for fitting models to experimental data in C++ and in Python. Wrote parts of custom syntax parser in Python for BNGL language. Created graphical user interface for PyBioNetFit in PyQt 5.</p></li>
  <li><p><a href="assets/ige.pdf">IgE Receptor Signaling</a>: My partner and I studied the allergy signal cascade by characterizing the IgE receptor in a mast cell. I wrote a computational model in BioNetGen simulating the interacting subunits which was used to predict certain rate constants and fit it to experimental data with BioNetFit. Qualified for ISEF 2016 in Phoenix, 2017 in Los Angeles.</p></li>
  <li><p><a href="braille.html">Refreshable Braille Display</a>: A single character braille display was created using memory wire which would pull or release pins based on input from an Arduino. 2015.</p></li>
  <li><p><a href="assets/ht.pdf">Headtracking: controlling your computer with your head</a>: Using the Wiimote, and safety glasses with infrared
LEDs, you could control your mouse pointer by moving your head and tilting it. 2013.</p></li>
  <h4><a href="3d.html">3D Modeling/Animation Work</a></h4>
</ul>
<h2>publications: </h2>
<ul>
  <li><span>Eshan D. Mitra, Ryan Suderman, Joshua Colvin, <b>Alexander Ionkov</b>, Andrew Hu, Herbert M. Sauro, Richard G. Posner, William S. Hlavacek, PyBioNetFit and the Biological Property Specification Language, iScience, Volume 19, 2019, Pages 1012-1036, ISSN 2589-0042, https://doi.org/10.1016/j.isci.2019.08.045.</span></li><br>
  <li><span>Hlavacek, W. S., Csicsery-Ronay, J. A., Baker, L. R., √Ålamo, M. D. C. R., <b>Ionkov, A.</b>, Mitra, E. D., ... & Thomas, B. R. (2019). A step-by-step guide to using BioNetFit. In Modeling Biomolecular Site Dynamics (pp. 391-419). Humana Press, New York, NY.</span></li><br>
  <li><span>Mitra, E., Suderman, R., <b>Ionkov, A.</b>, Hlavacek, W., & National Institutes of Health. (2018). PyBioNetFit. Los Alamos National Lab.(LANL), Los Alamos, NM (United States).</span></li>
</ul>
<h2>other places to find me: </h2>
<ul>
  <li><a href="https://twitter.com/i0nif" target="_blank">Twitter</a></li>
  <li><a href="http://github.com/ionif" target="_blank">GitHub</a></li>
  <li><a href="http://www.linkedin.com/in/aionkov" target="_blank">LinkedIn</a></li>
</ul>

</div>
</body>
</html>